{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.1.\n",
    " In Pandas, missing values are represented by None or NaN. We can identify missing value using: isnull() and notnull().\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Name   Age         City\n",
      "0    Alice  25.0     New York\n",
      "1      Bob   NaN  Los Angeles\n",
      "2  Charlie  30.0         None\n",
      "3     None  22.0      Chicago\n",
      "4     Emma   NaN       Boston\n",
      "    Name    Age   City\n",
      "0  False  False  False\n",
      "1  False   True  False\n",
      "2  False  False   True\n",
      "3   True  False  False\n",
      "4  False   True  False\n",
      "    Name    Age   City\n",
      "0   True   True   True\n",
      "1   True  False   True\n",
      "2   True   True  False\n",
      "3  False   True   True\n",
      "4   True  False   True\n",
      "    Name   Age      City\n",
      "0  Alice  25.0  New York\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "data = {'Name': ['Alice', 'Bob', 'Charlie', None, 'Emma'],\n",
    "        'Age': [25, None, 30, 22, None],\n",
    "        'City': ['New York', 'Los Angeles', None, 'Chicago', 'Boston']}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "print(df)\n",
    "print(df.isnull()) #Shows True where values are missing\n",
    "print(df.notnull()) #Shows True where values are not missing\n",
    "print(df.dropna()) #Drops rows with missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.2\n",
    "Imputation is the process of replacing missing or incomplete data with substituted values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame with missing values filled with 'Unknown':\n",
      "       Name      Age         City\n",
      "0    Alice     25.0     New York\n",
      "1      Bob  Unknown  Los Angeles\n",
      "2  Charlie     30.0      Unknown\n",
      "3  Unknown     22.0      Chicago\n",
      "4     Emma  Unknown       Boston\n",
      "\n",
      "DataFrame with 'Age' filled with mean:\n",
      "       Name        Age         City\n",
      "0    Alice  25.000000     New York\n",
      "1      Bob  25.666667  Los Angeles\n",
      "2  Charlie  30.000000         None\n",
      "3     None  22.000000      Chicago\n",
      "4     Emma  25.666667       Boston\n",
      "\n",
      "DataFrame with 'Age' filled with median:\n",
      "       Name   Age         City\n",
      "0    Alice  25.0     New York\n",
      "1      Bob  25.0  Los Angeles\n",
      "2  Charlie  30.0         None\n",
      "3     None  22.0      Chicago\n",
      "4     Emma  25.0       Boston\n",
      "\n",
      "DataFrame with 'Age' filled with mode:\n",
      "       Name   Age         City\n",
      "0    Alice  25.0     New York\n",
      "1      Bob  22.0  Los Angeles\n",
      "2  Charlie  30.0         None\n",
      "3     None  22.0      Chicago\n",
      "4     Emma  22.0       Boston\n",
      "\n",
      "DataFrame with forward fill:\n",
      "       Name   Age         City\n",
      "0    Alice  25.0     New York\n",
      "1      Bob  25.0  Los Angeles\n",
      "2  Charlie  30.0  Los Angeles\n",
      "3  Charlie  22.0      Chicago\n",
      "4     Emma  22.0       Boston\n",
      "\n",
      "DataFrame with backward fill:\n",
      "       Name   Age         City\n",
      "0    Alice  25.0     New York\n",
      "1      Bob  30.0  Los Angeles\n",
      "2  Charlie  30.0      Chicago\n",
      "3     Emma  22.0      Chicago\n",
      "4     Emma   NaN       Boston\n"
     ]
    }
   ],
   "source": [
    "df_filled = df.fillna(\"Unknown\")\n",
    "print(\"DataFrame with missing values filled with 'Unknown':\\n\", df_filled)\n",
    "\n",
    "# Create a copy of the DataFrame for numeric imputation\n",
    "df_numeric = df.copy()\n",
    "\n",
    "df_numeric['Age'] = df_numeric['Age'].fillna(df_numeric['Age'].mean())\n",
    "print(\"\\nDataFrame with 'Age' filled with mean:\\n\", df_numeric)\n",
    "\n",
    "df_numeric['Age'] = df['Age'].fillna(df['Age'].median())\n",
    "print(\"\\nDataFrame with 'Age' filled with median:\\n\", df_numeric)\n",
    "\n",
    "df_numeric['Age'] = df['Age'].fillna(df['Age'].mode()[0])\n",
    "print(\"\\nDataFrame with 'Age' filled with mode:\\n\", df_numeric)\n",
    "\n",
    "# Fill missing values using forward fill (previous value)\n",
    "df_ffill = df.ffill()\n",
    "print(\"\\nDataFrame with forward fill:\\n\", df_ffill)\n",
    "\n",
    "# Fill missing values using backward fill (next value)\n",
    "df_bfill = df.bfill()\n",
    "print(\"\\nDataFrame with backward fill:\\n\", df_bfill)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "DataFrame with forward fill:\n",
      "       Name   Age         City\n",
      "0    Alice  25.0     New York\n",
      "1      Bob  25.0  Los Angeles\n",
      "2  Charlie  30.0  Los Angeles\n",
      "3  Charlie  22.0      Chicago\n",
      "4     Emma  22.0       Boston\n",
      "\n",
      "DataFrame with backward fill:\n",
      "       Name   Age         City\n",
      "0    Alice  25.0     New York\n",
      "1      Bob  30.0  Los Angeles\n",
      "2  Charlie  30.0      Chicago\n",
      "3     Emma  22.0      Chicago\n",
      "4     Emma   NaN       Boston\n"
     ]
    }
   ],
   "source": [
    "# Fill missing values using forward fill (previous value)\n",
    "df_ffill = df.ffill()\n",
    "print(\"\\nDataFrame with forward fill:\\n\", df_ffill)\n",
    "\n",
    "# Fill missing values using backward fill (next value)\n",
    "df_bfill = df.bfill()\n",
    "print(\"\\nDataFrame with backward fill:\\n\", df_bfill)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.1\n",
    "Categorical variables can be encoded to convert non-numeric data into numerical values. The most common methods are label encoding and one-hot encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Fruit  Fruit_encoded\n",
      "0   Apple              0\n",
      "1  Banana              1\n",
      "2  Cherry              2\n",
      "3   Apple              0\n"
     ]
    }
   ],
   "source": [
    "# Label encoding( Assigns a unique integer to each category)\n",
    "import pandas as pd\n",
    "df = pd.DataFrame({'Fruit': ['Apple', 'Banana', 'Cherry', 'Apple']})\n",
    "df['Fruit_encoded'] = df['Fruit'].astype('category').cat.codes\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.2\n",
    "One-hot encoding is a technique used in data preprocessing to convert categorical variables into a numerical format that machine learning algorithms can use. Instead of representing a categorical value by assigning it a unique integer, one-hot encoding creates binary columns for each category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Fruit_Apple  Fruit_Banana  Fruit_Cherry\n",
      "0            1             0             0\n",
      "1            0             1             0\n",
      "2            0             0             1\n",
      "3            1             0             0\n"
     ]
    }
   ],
   "source": [
    "#One-Hot Encoding (Creates separate binary columns for each category)\n",
    "import pandas as pd\n",
    "df = pd.DataFrame({'Fruit': ['Apple', 'Banana', 'Cherry', 'Apple']})\n",
    "df_encoded = pd.get_dummies(df, columns=['Fruit']).astype(int)\n",
    "print(df_encoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3\n",
    " To find duplicate rows in a Pandas DataFrame, use .duplicated() method. To remove duplicate rows, use .drop_duplicates().\n",
    "The duplicated() method is used to identify duplicate rows in a DataFrame, while the drop_duplicates() method is used to remove duplicate rows from a DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    False\n",
      "1    False\n",
      "2    False\n",
      "3     True\n",
      "4    False\n",
      "dtype: bool\n",
      "      Name  Age\n",
      "0    Alice   25\n",
      "1      Bob   30\n",
      "2  Charlie   35\n",
      "4     Emma   28\n"
     ]
    }
   ],
   "source": [
    "import pandas as p\n",
    "data = {'Name': ['Alice', 'Bob', 'Charlie', 'Alice', 'Emma'],\n",
    "        'Age': [25, 30, 35, 25, 28]}\n",
    "df = pd.DataFrame(data)\n",
    "print(df.duplicated())  # Returns True for duplicate rows\n",
    "df_no_duplicates = df.drop_duplicates() # Drops duplicate rows\n",
    "print(df_no_duplicates)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4\n",
    "Scaling the features makes it easier for algorithms to find the optimal solution.Min-Max Scaling is suitable when we need to scale our data to a specific range and can handle the case when data needs to be bounded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial data:\n",
      "  Student  Height (sm)\n",
      "0       A          150\n",
      "1       B          160\n",
      "2       C          170\n",
      "3       D          180\n",
      "4       E          190\n",
      "Min-Max Scaling:\n",
      "  Student  Height (sm)\n",
      "0       A         0.00\n",
      "1       B         0.25\n",
      "2       C         0.50\n",
      "3       D         0.75\n",
      "4       E         1.00\n",
      "Z-Score Normalization:\n",
      "  Student  Height (sm)\n",
      "0       A    -1.414214\n",
      "1       B    -0.707107\n",
      "2       C     0.000000\n",
      "3       D     0.707107\n",
      "4       E     1.414214\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "data = pd.DataFrame({\n",
    "    'Student': ['A', 'B', 'C', 'D', 'E'],\n",
    "    'Height (sm)': [150, 160, 170, 180, 190]\n",
    "})\n",
    "\n",
    "# Min-Max Scaling\n",
    "min_max_scaler = MinMaxScaler()\n",
    "data_minmax = data.copy()\n",
    "data_minmax[['Height (sm)']] = min_max_scaler.fit_transform(data[['Height (sm)']])\n",
    "\n",
    "# Z-Score Normalization\n",
    "z_score_scaler = StandardScaler()\n",
    "data_zscore = data.copy()\n",
    "data_zscore[['Height (sm)']] = z_score_scaler.fit_transform(data[['Height (sm)']])\n",
    "\n",
    "print(\"Initial data:\")\n",
    "print(data)\n",
    "print(\"Min-Max Scaling:\")\n",
    "print(data_minmax)\n",
    "print(\"Z-Score Normalization:\")\n",
    "print(data_zscore)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An outlier is a data point that is noticeably different from the rest. They represent errors in measurement, bad data collection, or simply show variables not considered when collecting the data.\n",
    "The Z-Score method standardizes data and finds how far a data point is from the mean in terms of standard deviations. \n",
    "The IQR method calculates the range between the first quartile (25th percentile) and the third quartile (75th percentile). It helps identify outliers by setting boundaries.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Outliers IQR:\n",
      "10    200\n",
      "dtype: int64\n",
      "\n",
      "Outliers Z-score:\n",
      "10    200\n",
      "dtype: int64\n",
      "\n",
      "Weights without outliers (IQR method):\n",
      "0    70\n",
      "1    72\n",
      "2    68\n",
      "3    75\n",
      "4    69\n",
      "5    71\n",
      "6    80\n",
      "7    85\n",
      "8    90\n",
      "9    95\n",
      "dtype: int64\n",
      "\n",
      "Weights without outliers (Z-score method):\n",
      "0    70\n",
      "1    72\n",
      "2    68\n",
      "3    75\n",
      "4    69\n",
      "5    71\n",
      "6    80\n",
      "7    85\n",
      "8    90\n",
      "9    95\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "# Sample dataset with outliers\n",
    "weights = pd.Series([70, 72, 68, 75, 69, 71, 80, 85, 90, 95, 200])\n",
    "\n",
    "\n",
    "# Detecting outliers using IQR\n",
    "Q1 = weights.quantile(0.25)\n",
    "Q3 = weights.quantile(0.75)\n",
    "\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "lower_bound = Q1 - 1.5 * IQR\n",
    "upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "outliers_IQR = weights[(weights < lower_bound) | (weights > upper_bound)]\n",
    "print(\"\\nOutliers IQR:\")\n",
    "print(outliers_IQR)\n",
    "\n",
    "z_scores = stats.zscore(weights)\n",
    "\n",
    "outliers_zscore = weights[np.abs(z_scores) > 3]\n",
    "print(\"\\nOutliers Z-score:\")\n",
    "print(outliers_zscore)\n",
    "\n",
    "#Delete outliers\n",
    "weights_no_outliers_IQR = weights[(weights >= lower_bound) & (weights <= upper_bound)]\n",
    "print(\"\\nWeights without outliers (IQR method):\")\n",
    "print(weights_no_outliers_IQR)\n",
    "\n",
    "#Delete with Z-score\n",
    "weights_no_outliers_zscore = weights[np.abs(z_scores) <= 3]\n",
    "print(\"\\nWeights without outliers (Z-score method):\")\n",
    "print(weights_no_outliers_zscore)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
